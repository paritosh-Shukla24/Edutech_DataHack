Colorization of SAR Images Using GANs  
Introduction  
Synthetic aperture radar (SAR) images are used in various disciplines, including remote sensing, 
surveillance, and environmental monitoring. However, SAR images are monochromatic, which limits 
their interpretability. A GAN combined with a U -Net architecture is investigated here for the 
colorization of SAR image samples with dimensions of 256x256 pixels.  
U-Net Architecture  
U-Net is a convolutional neural network developed for image segmentation, but also accomplishes 
tasks such as image -to-image translation, including colorization. The architecture of U -Net has a two -
part structure -the encoder and the decoder.  
1.Encoder : It reduces the input image progressively using convolutional layers and max -
pooling. It captures the most salient features while reducing spatial dimensions.  
2.Decoder : It upsamples the encoded features back to the size of the input image using 
transposed convolutions, then concatenates the features with the corresponding encoder layer 
features to maintain spatial information.  
Convolutional Layers  
The convolution is one of the crucial operations within U -Net, wherein the filters slide across the 
input images for feature extraction. Each convolutional layer consists of several filters producing 
feature maps in the network that represent different noti ons within the image. In the case of SAR 
image colorization:  
•Convolution Operation : Each pixel in the output feature map is determined by obtaining 
the weighted within the cubic tense summation of pixel values. These weights are obtained 
from convolution filters.  
•Activation Function : The output from the convolution is subjected to a non -linear 
activation function  ReLU, to introduce non -linearity.  
Integration of GANs  
In this approach, a GAN consists of two neural networks: a generator (U -Net) and a discriminator. The 
generator transforms the input SAR images into colorized images, while the discriminator evaluates 
the authenticity of the generated images.  
•Training : The GAN is trained furthermore through adversarial loss, where the generator 
plays the adversary to synthesize images that can deceive the discriminator, while the 
discriminator tries to classify augmented images into real or fake classes. Besides this, the 
reconstruction loss can enforce that at least some aspects of the colorization feel 
perceptually plausible (for example, a mean squared error).  
Results  
The combination of U -Net and GANs for colorizing 256x256 pixel SAR images has shown promising 
results. The network is capable of producing visually appealing and realistic colorizations, enhancing 
interpretability and aiding in tasks such as land cover cla ssification and change detection.  
Before:    After:  
 
 
256x256 px  128x128 px  
